{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simclr--neu-lun.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VBdISgdn4acdH5cF8Go4ox-y6rgT9R2k",
      "authorship_tag": "ABX9TyM8q0aHwQ+sZgjcGp2sCRU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casual-lab/colab-notebooks/blob/main/simclr_neu_lun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 准备数据"
      ],
      "metadata": {
        "id": "GK2TBoSN9leM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "wget https://github.com/casual-lab/colab-notebooks/releases/download/v0.1/labeled.zip\n",
        "wget https://github.com/casual-lab/colab-notebooks/releases/download/v0.1/unlabeled.zip\n",
        "wget https://github.com/casual-lab/colab-notebooks/releases/download/v0.1/checkpoint_0200.pth.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKnf7IdCPyWs",
        "outputId": "c00a8da1-a3a0-4697-eaa2-431ce7a33619"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 03:53:02--  https://github.com/casual-lab/colab-notebooks/releases/download/v0.1/labeled.zip\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/479885109/818b3a95-3b57-4c68-9a1f-202a289ae64f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220421%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220421T035303Z&X-Amz-Expires=300&X-Amz-Signature=1bca8a7f195759c4072b628e59f0ffbee46ee21b0ee3248469379cfea814c2a4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=479885109&response-content-disposition=attachment%3B%20filename%3Dlabeled.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-21 03:53:03--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/479885109/818b3a95-3b57-4c68-9a1f-202a289ae64f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220421%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220421T035303Z&X-Amz-Expires=300&X-Amz-Signature=1bca8a7f195759c4072b628e59f0ffbee46ee21b0ee3248469379cfea814c2a4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=479885109&response-content-disposition=attachment%3B%20filename%3Dlabeled.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31103365 (30M) [application/octet-stream]\n",
            "Saving to: ‘labeled.zip’\n",
            "\n",
            "labeled.zip         100%[===================>]  29.66M   150MB/s    in 0.2s    \n",
            "\n",
            "2022-04-21 03:53:03 (150 MB/s) - ‘labeled.zip’ saved [31103365/31103365]\n",
            "\n",
            "--2022-04-21 03:53:03--  https://github.com/casual-lab/colab-notebooks/releases/download/v0.1/unlabeled.zip\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/479885109/85c40839-7337-4c94-822e-523585c1ed49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220421%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220421T035304Z&X-Amz-Expires=300&X-Amz-Signature=e2598f8ed4a9ba8403e4f73a682ca01f84fef774b5087dbc88120344b207bde0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=479885109&response-content-disposition=attachment%3B%20filename%3Dunlabeled.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-21 03:53:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/479885109/85c40839-7337-4c94-822e-523585c1ed49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220421%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220421T035304Z&X-Amz-Expires=300&X-Amz-Signature=e2598f8ed4a9ba8403e4f73a682ca01f84fef774b5087dbc88120344b207bde0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=479885109&response-content-disposition=attachment%3B%20filename%3Dunlabeled.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80328157 (77M) [application/octet-stream]\n",
            "Saving to: ‘unlabeled.zip’\n",
            "\n",
            "unlabeled.zip       100%[===================>]  76.61M  6.63MB/s    in 11s     \n",
            "\n",
            "2022-04-21 03:53:16 (6.67 MB/s) - ‘unlabeled.zip’ saved [80328157/80328157]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# rm -rf /content/labeled /content/unlabeled\n",
        "unzip -qn ./unlabeled.zip \n",
        "unzip -qn ./labeled.zip\n",
        "# cp -f ./unlabeled/* images/*\n",
        "# cp -f ./labeled/* images/*\n",
        "# unzip -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIjpNVZn9q8w",
        "outputId": "638258dd-b359-4c78-e9db-5d7393280b4e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练特征提取\n",
        "\n",
        "使用 SImCLR\n",
        "\n",
        "除了原本图像的三通道，还增加了边缘检测特征，通过1*1卷积映射到三通道\n",
        "\n",
        "数据是没有任何标签的图片\n",
        "\n"
      ],
      "metadata": {
        "id": "p9K8LUWTAFic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def get_filelist(dir):\n",
        "  flist = []\n",
        "  for home, dirs, files in os.walk(dir):\n",
        "    for filename in files:\n",
        "      if filename.split(\"-\")[1] == \"100\":\n",
        "        flist.append(os.path.join(home, filename))\n",
        "  return flist\n",
        "\n"
      ],
      "metadata": {
        "id": "bYiqSADBG4zK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "class GaussianBlur(object):\n",
        "  \"\"\"\n",
        "  blur a single image on CPU\n",
        "  \"\"\"\n",
        "  def __init__(self, kernel_size):\n",
        "    radias = kernel_size // 2\n",
        "    kernel_size = radias * 2 + 1\n",
        "    self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
        "                            stride=1, padding=0, bias=False, groups=3)\n",
        "    self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
        "                            stride=1, padding=0, bias=False, groups=3)\n",
        "    self.k = kernel_size\n",
        "    self.r = radias\n",
        "\n",
        "    self.blur = nn.Sequential(\n",
        "        nn.ReflectionPad2d(radias),\n",
        "        self.blur_h,\n",
        "        self.blur_v\n",
        "    )\n",
        "\n",
        "    self.pil_to_tensor = transforms.ToTensor()\n",
        "    self.tensor_to_pil = transforms.ToPILImage()\n",
        "\n",
        "  def __call__(self, img):\n",
        "    img = self.pil_to_tensor(img).unsqueeze(0)\n",
        "\n",
        "    sigma = np.random.uniform(0.1, 2.0)\n",
        "    x = np.arange(-self.r, self.r + 1)\n",
        "    x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
        "    x = x / x.sum()\n",
        "    x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
        "\n",
        "    self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
        "    self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img = self.blur(img)\n",
        "        img = img.squeeze()\n",
        "\n",
        "    img = self.tensor_to_pil(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "class AddCannyEdgeLayer(object):\n",
        "  def __init__(self, threadhold1, threadhold2):\n",
        "    self.th1 = threadhold1\n",
        "    self.th2 = threadhold2\n",
        "\n",
        "  def __call__(self, img: Image):\n",
        "    _img = np.array(img.convert('L'))\n",
        "    edge = cv.Canny(_img, 100, 200)[:, :, None]\n",
        "    # print(img.shape, _img.shape, edge.shape)\n",
        "    img = np.append(img, edge, axis=-1)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "B-eZoCGvWMHp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLearningViewGenerator(object):\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform, n_views=2):\n",
        "        self.base_transform = base_transform\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.base_transform(x) for i in range(self.n_views)]"
      ],
      "metadata": {
        "id": "117IyDlnYXgG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# import cv2 as cv\n",
        "\n",
        "# img = cv.imread(\"/content/unlabeled/105-100-1.jpg\", 0)\n",
        "# edges = cv.Canny(img,50,200)\n",
        "\n",
        "# # plt.figure(figsize=(60, 8))\n",
        "# # plt.subplot(211),plt.imshow(img, cmap = 'gray')\n",
        "# # plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "# # plt.subplot(212),plt.imshow(edges, cmap = 'gray')\n",
        "# # plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# print(np.array(Image.open('/content/unlabeled/105-100-1.jpg').convert('RGB')).shape, img.shape)\n",
        "# Image.fromarray(img.copy())"
      ],
      "metadata": {
        "id": "Pn5Ba_7cOMR_",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "class ContrastiveLearningDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_root, n_views) -> None:\n",
        "    transforms = self.get_simclr_pipeline_transform(80)\n",
        "    self.transforms = ContrastiveLearningViewGenerator(transforms, n_views)\n",
        "\n",
        "    flist = get_filelist(data_root)\n",
        "    self.img_boxes = []\n",
        "    h, w, _ = np.array(Image.open(flist[0])).shape\n",
        "    for f in flist:\n",
        "      for xmin, ymin in zip(range(0, h, h//8), range(0, w, w//8)):\n",
        "        img = Image.open(f).crop((xmin, ymin, xmin+h/8, ymin+w/8)).convert(\"RGB\")\n",
        "        self.img_boxes.append((f, img))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.img_boxes)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    imfile, img = self.img_boxes[idx]\n",
        "\n",
        "    if self.transforms != None:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "  @staticmethod\n",
        "  def get_simclr_pipeline_transform(size, s=1):\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "\n",
        "    trans = [transforms.RandomResizedCrop(size=size),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomApply([color_jitter], p=0.8),\n",
        "          transforms.RandomGrayscale(p=0.2),\n",
        "          GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "          AddCannyEdgeLayer(50, 200),\n",
        "          transforms.ToTensor()]\n",
        "    \n",
        "    data_transforms = transforms.Compose(trans)\n",
        "    return data_transforms\n"
      ],
      "metadata": {
        "id": "-Stv-DF6SNPf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "def save_config_file(model_checkpoints_folder, args):\n",
        "    if not os.path.exists(model_checkpoints_folder):\n",
        "        os.makedirs(model_checkpoints_folder)\n",
        "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
        "            yaml.dump(args, outfile, default_flow_style=False)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "metadata": {
        "id": "ApEjs1fbXDUJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ResNetSimCLR(nn.Module):\n",
        "\n",
        "    def __init__(self, base_model, out_dim):\n",
        "        super(ResNetSimCLR, self).__init__()\n",
        "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim),\n",
        "                            \"resnet50\": models.resnet50(pretrained=False, num_classes=out_dim)}\n",
        "\n",
        "        self.backbone = self._get_basemodel(base_model)\n",
        "        dim_mlp = self.backbone.fc.in_features\n",
        "\n",
        "        # add mlp projection head\n",
        "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(4, 3, kernel_size=1),\n",
        "            self.backbone\n",
        "        )\n",
        "\n",
        "    def _get_basemodel(self, model_name):\n",
        "        try:\n",
        "            model = self.resnet_dict[model_name]\n",
        "        except KeyError:\n",
        "            raise NotImplementedError(\n",
        "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
        "        else:\n",
        "            return model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ],
      "metadata": {
        "id": "JZ9pSD-Ff5YS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "class SimCLR(object):\n",
        "\n",
        "    def __init__(self, model, optimizer, scheduler, **kw):\n",
        "        self.args = kw\n",
        "\n",
        "        self.model = model.to(self.args['device'])\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.log_dir = args['log_dir']\n",
        "        # self.writer = SummaryWriter()\n",
        "        \n",
        "        if 'resume' in args.keys() and args['resume']:\n",
        "          assert 'resume_model_path' in args.keys()\n",
        "          checkpoint = torch.load(args['resume_model_path'], map_location=args['device'])\n",
        "          state_dict = checkpoint['state_dict']\n",
        "          model.load_state_dict(state_dict)\n",
        "\n",
        "        logging.basicConfig(\n",
        "            filename=os.path.join(self.log_dir, 'training.log'), \n",
        "            level=logging.DEBUG)\n",
        "        \n",
        "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args['device'])\n",
        "        self.evals = {}\n",
        "    \n",
        "    def _push_eval(self, ekey, eidx, eval):\n",
        "      if ekey not in self.evals.keys():\n",
        "        self.evals[ekey] = ([],[])\n",
        "      self.evals[ekey][0].append(eidx)\n",
        "      self.evals[ekey][1].append(eval)\n",
        "\n",
        "    def _get_last_eval(self, ekey):\n",
        "      if ekey not in self.evals.keys():\n",
        "        return -1\n",
        "      return self.evals[ekey][1][-1]\n",
        "\n",
        "    def get_eval(self, ekey):\n",
        "      return self.evals[ekey]\n",
        "\n",
        "    def info_nce_loss(self, features):\n",
        "\n",
        "        labels = torch.cat([torch.arange(self.args['batch_size']) for i in range(self.args['n_views'])], dim=0)\n",
        "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "        labels = labels.to(self.args['device'])\n",
        "\n",
        "        features = F.normalize(features, dim=1)\n",
        "\n",
        "        similarity_matrix = torch.matmul(features, features.T)\n",
        "        # assert similarity_matrix.shape == (\n",
        "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
        "        # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "        # discard the main diagonal from both: labels and similarities matrix\n",
        "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args['device'])\n",
        "        labels = labels[~mask].view(labels.shape[0], -1)\n",
        "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "        # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "        # select and combine multiple positives\n",
        "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
        "\n",
        "        # select only the negatives the negatives\n",
        "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
        "\n",
        "        logits = torch.cat([positives, negatives], dim=1)\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args['device'])\n",
        "\n",
        "        logits = logits / self.args['temperature']\n",
        "        return logits, labels\n",
        "\n",
        "    def train(self, train_loader):\n",
        "\n",
        "        scaler = GradScaler(enabled=self.args['fp16_precision'])\n",
        "\n",
        "        # save config file\n",
        "        save_config_file(self.log_dir, self.args)\n",
        "\n",
        "        n_iter = 0\n",
        "        logging.info(f\"Start SimCLR training for {self.args['epochs']} epochs.\")\n",
        "        logging.info(f\"Training with gpu: {self.args['enable_cuda']}.\")\n",
        "\n",
        "        for epoch_counter in range(self.args['epochs']):\n",
        "            cus_bar_format = '[Epoch:{:4d}]'.format(epoch_counter)\n",
        "            cus_bar_format += '{l_bar}{bar}{r_bar}' \n",
        "            cus_bar_format += f\"Step:{n_iter}\\t Loss:{self._get_last_eval('loss'):.4f}\\t acc/total:{self._get_last_eval('acc/total'):.2f} acc/top1:{self._get_last_eval('acc/top1'):.2f}\\t acc/top5:{self._get_last_eval('acc/top5'):.2f}\\t learning_rate:{self.scheduler.get_lr()[0]}\"\n",
        "            for images in tqdm(train_loader, bar_format=cus_bar_format):\n",
        "                images = torch.cat(images, dim=0)\n",
        "\n",
        "                images = images.to(self.args['device'])\n",
        "\n",
        "                with autocast(enabled=self.args['fp16_precision']):\n",
        "                    features = self.model(images)\n",
        "                    logits, labels = self.info_nce_loss(features)\n",
        "                    loss = self.criterion(logits, labels)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                scaler.step(self.optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                if n_iter % self.args['log_every_n_steps'] == 0:\n",
        "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
        "                    logging.debug(f\"Step: {n_iter}\\tLoss: {loss}\\t acc/top1: {top1[0]}\\t acc/top5: {top5[0]}\\t learning_rate: {self.scheduler.get_lr()[0]}\")\n",
        "\n",
        "                    self._push_eval('loss', int(n_iter), float(loss.cpu()))\n",
        "                    self._push_eval('acc/top1', int(n_iter), float(top1[0].cpu()))\n",
        "                    self._push_eval('acc/top5', int(n_iter), float(top5[0].cpu()))\n",
        "                    self._push_eval('learning_rate', int(n_iter), float(self.scheduler.get_lr()[0]))\n",
        "\n",
        "                n_iter += 1\n",
        "\n",
        "            # warmup for the first 10 epochs\n",
        "            if epoch_counter >= 10:\n",
        "                self.scheduler.step()\n",
        "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0].cpu()}\")\n",
        "            self._push_eval('acc/total', int(n_iter), top1[0])\n",
        "\n",
        "        logging.info(\"Training has finished.\")\n",
        "        # save model checkpoints\n",
        "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args['epochs'])\n",
        "        save_checkpoint({\n",
        "            'epoch': self.args['epochs'],\n",
        "            'arch': self.args['arch'],\n",
        "            'state_dict': self.model.state_dict(),\n",
        "            'optimizer': self.optimizer.state_dict(),\n",
        "        }, is_best=False, filename=os.path.join(self.log_dir, checkpoint_name))\n",
        "        logging.info(f\"Model checkpoint and metadata has been saved at {self.log_dir}.\")\n",
        "\n",
        "        for name, vdict in self.evals.items():\n",
        "          name_ = name.replace('/', '-')\n",
        "          filename = os.path.join(self.log_dir, f'{name_}.csv')\n",
        "          with open(filename, mode='w') as fobj:\n",
        "            for i, v in zip(vdict[0], vdict[1]):\n",
        "              fobj.write(f'{i:d},{v:f}\\n')\n",
        "        logging.info(f\"Model evals has been saved at {self.log_dir}.\")"
      ],
      "metadata": {
        "id": "5WYRysRKWmsH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import models\n",
        "\n",
        "# check if gpu training is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    cudnn.deterministic = True\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "dataset = ContrastiveLearningDataset('./unlabeled', 4)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=10, shuffle=True,\n",
        "    num_workers=2, pin_memory=True, drop_last=True)\n",
        "\n",
        "model = ResNetSimCLR(base_model=\"resnet18\", out_dim=64)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00006, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2, last_epoch=-1)\n",
        "\n",
        "args = {\n",
        "    'device': device,\n",
        "    'batch_size': 10,\n",
        "    'temperature': 0.07,\n",
        "    'fp16_precision': True,\n",
        "    'log_every_n_steps': 100,\n",
        "    'save_every_n_epochs': 50,\n",
        "    'epochs': 0,    # 仅模型评估，设为 0\n",
        "    'arch': 'resnet18',\n",
        "    'enable_cuda' : torch.cuda.is_available(),\n",
        "    'n_views': 4, \n",
        "    'resume':True, \n",
        "    'resume_model_path': './checkpoint_0200.pth.tar',\n",
        "    'log_dir': './'\n",
        "}\n",
        "\n",
        "simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, **args)\n",
        "simclr.train(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZxMykeGXLA2",
        "outputId": "3d8cfbcc-efe8-4018-b2d5-19668da2c8b2",
        "cellView": "code"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import datetime\n",
        "\n",
        "# plt.figure(0)\n",
        "# plt.plot(simclr.get_eval('loss')[0], simclr.get_eval('loss')[1])\n",
        "# f = plt.gcf()  \n",
        "# f.savefig(f'./loss.png')\n",
        "# f.clear()  \n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "-j6qbuuOTW8t"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 实验使用训练好的编码器"
      ],
      "metadata": {
        "id": "1XVEirO-pN0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 准备 带标签的 bounding box 数据"
      ],
      "metadata": {
        "id": "DyYMbmzkBwHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"labelbox[data]\""
      ],
      "metadata": {
        "id": "wDAjiyjppTh5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from labelbox import Client, OntologyBuilder\n",
        "from labelbox.data.annotation_types import Geometry\n",
        "from labelbox.data.annotation_types.collection import LabelList\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "B3FGNupcpgrC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegClsName:\n",
        "  VESSEL = \"血管\"\n",
        "  BRONCHUS = \"支气管\"\n",
        "\n",
        "  def get_all_names():\n",
        "    return ['支气管', '血管']\n",
        "\n",
        "class VesselRatingName:\n",
        "  D = \"D血管周围浸润\"\n",
        "\n",
        "class BronchusRatingName:\n",
        "  A = \"A支气管浸润\"\n",
        "  B = \"B支气管浸润定性\"\n",
        "  C = \"C支气管腔渗出\"\n",
        "\n",
        "  def get_all_names():\n",
        "    return [\"A支气管浸润\", \"B支气管浸润定性\", \"C支气管腔渗出\"]"
      ],
      "metadata": {
        "id": "Xu6pEirnpkBj"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbDFwMTI0NncwMnZ0MHo3cGdieGthaGRoIiwib3JnYW5pemF0aW9uSWQiOiJjbDFwMTI0NmwwMnZzMHo3cDJhZXlicXBxIiwiYXBpS2V5SWQiOiJjbDF3N2NxY3o0M2tiMHpiaWh3ZjE0Y2t5Iiwic2VjcmV0IjoiNTExZGFlOTQ4NzQ0MjI0YjQ4MjI1MWZmZTk0NDJkMDkiLCJpYXQiOjE2NDk3NzE0OTcsImV4cCI6MjI4MDkyMzQ5N30.afEQowJg4cIlz2yZJMOQE8r5NuzAglwcifskm8GfZQY\"\n",
        "PROJECT_ID = \"cl1vkawjv12se0zdr5o4vf9xu\"\n",
        "client = Client(api_key=API_KEY)\n",
        "project = client.get_project(PROJECT_ID)\n",
        "labels = project.label_generator().as_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFo8AzAFpmlS",
        "outputId": "89dcb37c-73a7-4266-c7b3-fea7c5d78db7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/labelbox/data/annotation_types/classification/classification.py:85: UserWarning: Dropdown classification is deprecated and will be removed in a future release\n",
            "  warnings.warn(\"Dropdown classification is deprecated and will be \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from threading import Thread\n",
        "\n",
        "def get_box(a):\n",
        "  mask = a.value.draw()[:, :, 0]\n",
        "  pos = np.where(mask != 0)\n",
        "  xmin = np.min(pos[1])\n",
        "  xmax = np.max(pos[1])\n",
        "  ymin = np.min(pos[0])\n",
        "  ymax = np.max(pos[0])\n",
        "  # 只针对 ResNet18 的约束\n",
        "  if xmax - xmin > 32 or ymax - ymin > 32: \n",
        "    return [xmin, ymin, xmax, ymax] \n",
        "  return None\n",
        "\n",
        "def data_enhance(bs, rs):\n",
        "  data_dict = {}\n",
        "  for b,r in zip(bs, rs):\n",
        "    if r not in data_dict.keys(): data_dict[r] = []\n",
        "    data_dict[r].append(b)\n",
        "  ctr = Counter(rs)\n",
        "  max_num = max(list(ctr.values()))\n",
        "  for r in data_dict.keys():\n",
        "    if ctr[r] >= max_num: continue\n",
        "    bs.extend(np.random.choice(data_dict[r], size=max_num-ctr[r]))\n",
        "    rs.extend([r] * (max_num - ctr[r]))\n",
        "    assert len(bs)==len(rs)\n",
        "\n",
        "def get_box_ratings(lb_labels: LabelList, cls_name, rating_name, n_workers=4, balance=False):\n",
        "\n",
        "  boxes = []\n",
        "  ratings = []\n",
        "\n",
        "  def parse(lb, a):\n",
        "    if a.name != cls_name: return\n",
        "    rating = [float(c.value.answer.name) for c in a.classifications if c.name == rating_name]\n",
        "    if len(rating) == 0: return\n",
        "    rating = rating[0]\n",
        "    box = get_box(a)\n",
        "    if box == None: return\n",
        "    im = lb.data.value[box[1]:box[3]+1, box[0]:box[2]+1]\n",
        "    \n",
        "    boxes.append(im)\n",
        "    ratings.append(rating)\n",
        "\n",
        "  class ParsingThread(Thread):\n",
        "    def __init__(self, lb, a):\n",
        "      Thread.__init__(self)\n",
        "      self.lb = lb\n",
        "      self.a = a\n",
        "\n",
        "    def run(self):\n",
        "      parse(self.lb, self.a)\n",
        "\n",
        "  ths = []\n",
        "  for lb in lb_labels:\n",
        "    for a in lb.object_annotations():\n",
        "      ths.append(ParsingThread(lb, a))\n",
        "\n",
        "  for t in ths[:n_workers]: t.start()\n",
        "  for t1, t2 in zip(ths, ths[n_workers:]):\n",
        "    t1.join()\n",
        "    t2.start()\n",
        "  for t in ths[-n_workers:]: t.join()\n",
        "\n",
        "  if balance: data_enhance(boxes, ratings)\n",
        "\n",
        "  boxes = [Image.fromarray(im) for im in boxes]\n",
        "  return boxes, np.array(ratings)\n"
      ],
      "metadata": {
        "id": "Hcissylomjel"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import transforms as T\n",
        "\n",
        "def get_transform():\n",
        "    transforms = [\n",
        "        T.Resize((80, 80)),\n",
        "        AddCannyEdgeLayer(50, 200), \n",
        "        T.ToTensor()\n",
        "    ]\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "CrFpBO4AxrBa"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "import cv2 as cv\n",
        "import pywt\n",
        "import pywt.data\n",
        "\n",
        "def get_feature_model(train=False): \n",
        "  _m = model\n",
        "  if not train: _m.eval()\n",
        "  else: _m.train()\n",
        "  return model\n",
        "\n",
        "def get_flatten_rating_feature(im, transforms):\n",
        "  net = get_feature_model()\n",
        "  im = im.convert('RGB')\n",
        "  \n",
        "  # 抽象特征\n",
        "  tensor_im = transforms(im.copy()).unsqueeze(0).to(device)\n",
        "  ftr = np.array(net(tensor_im).cpu().detach()).flatten()\n",
        "\n",
        "  grey_im = np.array(im.copy().convert('L'))\n",
        "\n",
        "  # # 像素特征\n",
        "  # ftr = np.append(ftr, np.array(im.copy().resize((200, 200))).flatten(), axis=0)\n",
        "\n",
        "  # 灰度共存矩阵\n",
        "  compress_gray = np.digitize(grey_im, np.linspace(0, 255, 64))\n",
        "  comatrix = greycomatrix(grey_im, np.linspace(10, 20, num=4), \n",
        "                [0, np.pi / 4, np.pi / 2, np.pi * 3 / 4],\n",
        "                256, symmetric=True, normed=True)\n",
        "  for prop in {'contrast', 'dissimilarity','homogeneity', 'energy', 'correlation', 'ASM'}:\n",
        "    temp = greycoprops(comatrix, prop).flatten()\n",
        "    ftr = np.append(ftr, temp, axis=0)\n",
        "\n",
        "  # 小波包变换能量系数\n",
        "  n_level = 3\n",
        "  re = []  #第n层所有节点的分解系数\n",
        "  wp = pywt.WaveletPacket2D(data=grey_im, wavelet='db1',mode='symmetric',maxlevel=n_level)\n",
        "  for p in [n.path for nodes in wp.get_level(n_level, 'freq') for n in nodes]:\n",
        "    ftr = np.append(ftr, np.array([float(pow(np.linalg.norm(wp[p].data,ord=None),2))]), axis=0)\n",
        "  \n",
        "  return ftr"
      ],
      "metadata": {
        "id": "rodtzP_RvUat"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = get_box_ratings(labels, SegClsName.BRONCHUS, BronchusRatingName.B, n_workers=8)\n",
        "X = np.array([get_flatten_rating_feature(im, get_transform()) for im in X])\n",
        "\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "hNquZG5fL6Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34c6f24-de90-4a0b-f900-3dee70a23fae"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 224), (108,))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.2)"
      ],
      "metadata": {
        "id": "MfFlCs553jDe"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import KBinsDiscretizer, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "def try_(tree_depth=3):\n",
        "    svr_boost = AdaBoostRegressor(base_estimator=SVR(C=1.0, epsilon=0.2))\n",
        "    tr_pip = Pipeline([('discretizer', KBinsDiscretizer(n_bins=5, encode=\"onehot\", strategy='uniform')), \n",
        "            ('tree',DecisionTreeRegressor(max_depth=tree_depth))])\n",
        "    tree_boost = AdaBoostRegressor(base_estimator=tr_pip) \n",
        "    # poly_pip = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
        "    #             ('linear', LinearRegression(fit_intercept=False))])\n",
        "    # poly_boost = AdaBoostRegressor(base_estimator=poly_pip)\n",
        "    estimators = [\n",
        "      ('svr', svr_boost), ('tree', tree_boost)\n",
        "    ]\n",
        "\n",
        "    stk_reg = StackingRegressor(estimators=estimators, final_estimator=MLPRegressor(random_state=1, max_iter=500))\n",
        "    vot_reg = VotingRegressor(estimators=estimators)\n",
        "\n",
        "    vot_reg.fit(X_train, y_train)         # 全部特征\n",
        "    test_s, train_s = vot_reg.score(X_test, y_test),vot_reg.score(X_train, y_train)\n",
        "    print(test_s, train_s)\n",
        "    vot_reg.fit(X_train[:, :64], y_train)     # 只取抽象特征 \n",
        "    test_s, train_s = vot_reg.score(X_test[:, :64], y_test),vot_reg.score(X_train[:, :64], y_train)\n",
        "    print(test_s, train_s)\n",
        "    vot_reg.fit(X_train[:, 64:], y_train)     # 只取手工特征\n",
        "    test_s, train_s = vot_reg.score(X_test[:, 64:], y_test),vot_reg.score(X_train[:, 64:], y_train)\n",
        "    print(test_s, train_s)\n",
        "    \n",
        "    stk_reg.fit(X_train, y_train)         # 全部特征\n",
        "    test_s, train_s = stk_reg.score(X_test, y_test),stk_reg.score(X_train, y_train)\n",
        "    print(test_s, train_s)\n",
        "    stk_reg.fit(X_train[:, :64], y_train)     # 只取抽象特征\n",
        "    test_s, train_s = stk_reg.score(X_test[:, :64], y_test),stk_reg.score(X_train[:, :64], y_train)\n",
        "    print(test_s, train_s)\n",
        "    stk_reg.fit(X_train[:, 64:], y_train)     # 只取手工特征\n",
        "    test_s, train_s = stk_reg.score(X_test[:, 64:], y_test),stk_reg.score(X_train[:, 64:], y_train)\n",
        "    print(test_s, train_s)\n",
        "\n",
        "    return test_s, train_s\n",
        "\n",
        "try_(6)"
      ],
      "metadata": {
        "id": "WlthT5HnJPBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ba40a2-eef7-4708-ec05-0da16701291b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00397589791325037 0.7580721473809812\n",
            "-0.2471913232242653 0.8266782138101216\n",
            "0.0712434732081122 0.7579150061004943\n",
            "0.03884107127971648 0.32475575677329116\n",
            "0.0020268301365905517 0.4128777039036372\n",
            "0.03542056260049098 0.7857943018937021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.03542056260049098, 0.7857943018937021)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_pip = Pipeline([('discretizer', KBinsDiscretizer(n_bins=5, encode=\"onehot\", strategy='uniform')), \n",
        "          ('tree',DecisionTreeRegressor(max_depth=4))])\n",
        "tree_boost = AdaBoostRegressor(base_estimator=tr_pip)"
      ],
      "metadata": {
        "id": "KxCleybgp5PC"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_boost.fit(X_train[:, 64:], y_train)\n",
        "tree_boost.score(X_test[:, 64:], y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeRJ0p3KJPTq",
        "outputId": "631ec76e-92a8-45b8-dfbc-2cb8384d44df"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19439908046808774"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_boost.fit(X_train, y_train)\n",
        "tree_boost.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AngwsAgeZ2be",
        "outputId": "9f99171a-7f98-4ef5-82cf-35f3c0528ba7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.018587890316498434"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_boost.fit(X_train[:, :64], y_train)\n",
        "tree_boost.score(X_test[:, :64], y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9axuYjDrqv2E",
        "outputId": "e61bdcb0-8a83-4240-b484-34d9185cbe76"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2068121683789399"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}